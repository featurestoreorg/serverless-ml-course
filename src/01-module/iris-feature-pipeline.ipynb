{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower - Feature Pipeline\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Run in either \"Backfill\" or \"Normal\" operation. \n",
    "2. IF *BACKFILL==True*, we will load our DataFrame with data from the iris.csv file \n",
    "\n",
    "   ELSE *BACKFILL==False*, we will load our DataFrame with one synthetic Iris Flower sample \n",
    "3. Write our DataFrame to a Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[55 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/error.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/serializing_producer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/deserializing_consumer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/avro.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/error.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/json_schema.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/schema_registry_client.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/protobuf.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/serialization\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/serialization/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/serialization\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/admin\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/admin/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/admin\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/error.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/cached_schema_registry_client.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/load.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/verifiable_client.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/verifiable_consumer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/verifiable_producer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro/serializer\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/serializer/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro/serializer\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/serializer/message_serializer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro/serializer\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'confluent_kafka.cimpl' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/yashzambre/miniconda3/include -arch arm64 -I/Users/yashzambre/miniconda3/include -fPIC -O2 -isystem /Users/yashzambre/miniconda3/include -arch arm64 -I/Users/yashzambre/miniconda3/include/python3.9 -c /private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/Admin.c -o build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/Admin.o\n",
      "  \u001b[31m   \u001b[0m In file included from /private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/Admin.c:17:\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/confluent_kafka.h:23:10: fatal error: 'librdkafka/rdkafka.h' file not found\n",
      "  \u001b[31m   \u001b[0m #include <librdkafka/rdkafka.h>\n",
      "  \u001b[31m   \u001b[0m          ^~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for confluent-kafka\u001b[0m\u001b[31m\n",
      "\u001b[0m  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for confluent-kafka\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[57 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /Users/yashzambre/miniconda3/lib/python3.9/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/error.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/serializing_producer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/deserializing_consumer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/avro.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/error.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/json_schema.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/schema_registry_client.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/schema_registry/protobuf.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/schema_registry\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/serialization\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/serialization/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/serialization\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/admin\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/admin/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/admin\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/error.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/cached_schema_registry_client.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/load.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/verifiable_client.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/verifiable_consumer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/kafkatest/verifiable_producer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/kafkatest\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro/serializer\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/serializer/__init__.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro/serializer\n",
      "  \u001b[31m   \u001b[0m copying src/confluent_kafka/avro/serializer/message_serializer.py -> build/lib.macosx-11.1-arm64-cpython-39/confluent_kafka/avro/serializer\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'confluent_kafka.cimpl' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src\n",
      "  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /Users/yashzambre/miniconda3/include -arch arm64 -I/Users/yashzambre/miniconda3/include -fPIC -O2 -isystem /Users/yashzambre/miniconda3/include -arch arm64 -I/Users/yashzambre/miniconda3/include/python3.9 -c /private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/Admin.c -o build/temp.macosx-11.1-arm64-cpython-39/private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/Admin.o\n",
      "  \u001b[31m   \u001b[0m In file included from /private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/Admin.c:17:\n",
      "  \u001b[31m   \u001b[0m /private/var/folders/l1/l3h53cgx7cd828rt1jbs74xc0000gn/T/pip-install-usb0ymxm/confluent-kafka_36e1c90b553047f2b996695474447242/src/confluent_kafka/src/confluent_kafka.h:23:10: fatal error: 'librdkafka/rdkafka.h' file not found\n",
      "  \u001b[31m   \u001b[0m #include <librdkafka/rdkafka.h>\n",
      "  \u001b[31m   \u001b[0m          ^~~~~~~~~~~~~~~~~~~~~~\n",
      "  \u001b[31m   \u001b[0m 1 error generated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m confluent-kafka\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U hopsworks --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set **BACKFILL=True** if you want to create features from the iris.csv file containing historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "BACKFILL=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Functions\n",
    "\n",
    "These synthetic data functions can be used to create a DataFrame containing a single Iris Flower sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nRmFM7vcbpHA",
    "outputId": "d920d168-9818-40c5-c292-4cf0afcbbcfd"
   },
   "outputs": [],
   "source": [
    "def generate_flower(name, sepal_len_max, sepal_len_min, sepal_width_max, sepal_width_min, \n",
    "                    petal_len_max, petal_len_min, petal_width_max, petal_width_min):\n",
    "    \"\"\"\n",
    "    Returns a single iris flower as a single row in a DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({ \"sepal_length\": [random.uniform(sepal_len_max, sepal_len_min)],\n",
    "                       \"sepal_width\": [random.uniform(sepal_width_max, sepal_width_min)],\n",
    "                       \"petal_length\": [random.uniform(petal_len_max, petal_len_min)],\n",
    "                       \"petal_width\": [random.uniform(petal_width_max, petal_width_min)]\n",
    "                      })\n",
    "    df['variety'] = name\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_random_iris_flower():\n",
    "    \"\"\"\n",
    "    Returns a DataFrame containing one random iris flower\n",
    "    \"\"\"\n",
    "    virginica_df = generate_flower(\"Virginica\", 8, 5.5, 3.8, 2.2, 7, 4.5, 2.5, 1.4)\n",
    "    versicolor_df = generate_flower(\"Versicolor\", 7.5, 4.5, 3.5, 2.1, 3.1, 5.5, 1.8, 1.0)\n",
    "    setosa_df =  generate_flower(\"Setosa\", 6, 4.5, 4.5, 2.3, 1.2, 2, 0.7, 0.3)\n",
    "\n",
    "    # randomly pick one of these 3 and write it to the featurestore\n",
    "    pick_random = random.uniform(0,3)\n",
    "    if pick_random >= 2:\n",
    "        iris_df = virginica_df\n",
    "    elif pick_random >= 1:\n",
    "        iris_df = versicolor_df\n",
    "    else:\n",
    "        iris_df = setosa_df\n",
    "\n",
    "    return iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backfill or create new synthetic input data\n",
    "\n",
    "You can run this pipeline in either *backfill* or *synthetic-data* mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if BACKFILL == True:\n",
    "    iris_df = pd.read_csv(\"https://repo.hops.works/master/hopsworks-tutorials/data/iris.csv\")\n",
    "else:\n",
    "    iris_df = get_random_iris_flower()\n",
    "    \n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate with Hopsworks using your API Key\n",
    "\n",
    "Hopsworks will prompt you to paste in your API key and provide you with a link to find your API key if you have not stored it securely already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and write to a feature group - primary keys\n",
    "\n",
    "To prevent duplicate entries, Hopsworks requires that each DataFame has a *primary_key*. \n",
    "A *primary_key* is one or more columns that uniquely identify the row. Here, we assume\n",
    "that each Iris flower has a unique combination of (\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\")\n",
    "feature values. If you randomly generate a sample that already exists in the feature group, the insert operation will fail.\n",
    "\n",
    "The *feature group* will create its online schema using the schema of the Pandas DataFame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_fg = fs.get_or_create_feature_group(name=\"iris\",\n",
    "                                  version=1,\n",
    "                                  primary_key=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"],\n",
    "                                  description=\"Iris flower dataset\"\n",
    "                                 )\n",
    "iris_fg.insert(iris_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f4f429d08d0854cc906e6e07172541c8c0eac01d210643df7b98150b1e3e6e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
